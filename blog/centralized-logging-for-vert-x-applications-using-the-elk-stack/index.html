<!DOCTYPE html><html lang=en><head><title>Centralized logging for Vert.x applications using the ELK stack</title><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta content="width=device-width,initial-scale=1" name=viewport><meta content="Eclipse Vert.x is a tool-kit for building reactive applications on the JVM." name=description><link href=https://vertx.tk/stylesheets/main.css media=screen rel=stylesheet><link href=https://vertx.tk/stylesheets/font-awesome.min.css media=screen rel=stylesheet><link href=https://vertx.tk/javascripts/styles/rainbow.min.css media=screen rel=stylesheet><!--[if lt IE 9]><script src="http://static.jboss.org/theme/js/libs/html5/pre3.6/html5.min.js"></script><![endif]--><link rel=apple-touch-icon sizes=57x57 href=https://vertx.tk/assets/favicons/vertx-favicon-7/apple-touch-icon-57x57.png><link rel=apple-touch-icon sizes=60x60 href=https://vertx.tk/assets/favicons/vertx-favicon-7/apple-touch-icon-60x60.png><link rel=apple-touch-icon sizes=72x72 href=https://vertx.tk/assets/favicons/vertx-favicon-7/apple-touch-icon-72x72.png><link rel=apple-touch-icon sizes=76x76 href=https://vertx.tk/assets/favicons/vertx-favicon-7/apple-touch-icon-76x76.png><link rel=apple-touch-icon sizes=114x114 href=https://vertx.tk/assets/favicons/vertx-favicon-7/apple-touch-icon-114x114.png><link rel=apple-touch-icon sizes=120x120 href=https://vertx.tk/assets/favicons/vertx-favicon-7/apple-touch-icon-120x120.png><link rel=apple-touch-icon sizes=144x144 href=https://vertx.tk/assets/favicons/vertx-favicon-7/apple-touch-icon-144x144.png><link rel=apple-touch-icon sizes=152x152 href=https://vertx.tk/assets/favicons/vertx-favicon-7/apple-touch-icon-152x152.png><link rel=apple-touch-icon sizes=180x180 href=https://vertx.tk/assets/favicons/vertx-favicon-7/apple-touch-icon-180x180.png><link rel=icon type=image/png href=https://vertx.tk/assets/favicons/vertx-favicon-7/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=https://vertx.tk/assets/favicons/vertx-favicon-7/android-chrome-192x192.png sizes=192x192><link rel=icon type=image/png href=https://vertx.tk/assets/favicons/vertx-favicon-7/favicon-96x96.png sizes=96x96><link rel=icon type=image/png href=https://vertx.tk/assets/favicons/vertx-favicon-7/favicon-16x16.png sizes=16x16><link rel=manifest href=https://vertx.tk/assets/favicons/vertx-favicon-7/manifest.json><link rel=mask-icon href=https://vertx.tk/assets/favicons/vertx-favicon-7/safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content=#7d3194><meta name=msapplication-TileImage content=https://vertx.tk/assets/favicons/vertx-favicon-7/mstile-144x144.png><meta name=theme-color content=#ffffff><link href="https://fonts.googleapis.com/css?family=Ubuntu:400,500,700,400italic" rel=stylesheet type=text/css><link rel=alternate type=application/rss+xml title=RSS href=https://vertx.tk/feed.xml><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-30144458-1', 'auto');
    ga('create', 'UA-71153120-1', 'auto', 'tracker');
    ga('send', 'pageview');
    ga('tracker.send', 'pageview');</script><style>.page-link-to-github {
      position: relative;
      z-index: 1;
      display: inline-block;
      border: 1px solid #782B90;
      border-radius: 5px;
      color: #782B90;
      font-size: 12px;
      padding: 4px 10px;
      text-decoration: none;
      background-color: #ffffff;
    }
    .page-link-to-github:hover {
      color: #ffffff;
      border-color: #ffffff;
      background-color: #782B90;
    }

    .page-link-to-github .github-icon {
      position: absolute;
      display: inline-block;
      width: 20px;
      height: 20px;
      /*background-position: -50px 0*/
      background: url('https://vertx.tk/assets/github.png') no-repeat 0 0;
    }

    @media (-webkit-min-device-pixel-ratio: 2),(min-resolution:192dpi) {
      .page-link-to-github .github-icon {
        background-image:url('https://vertx.tk/assets/github@2x.png');
        background-size: 150px auto
      }
    }

    .page-link-to-github:hover .github-icon {
      /*background-position: 0 0*/
      background-position: -100px 0
    }
    .text {
      text-decoration: underline
    }
    .page-link-to-github .text {
      padding-left: 27px
    }
    .text {
      padding-right: 8px
    }
    .page-link-to-github {
      float: right;
      top: 4px
    }</style></head><body><a href="http://www.reactivemanifesto.org/" id=reactive-manifesto-banner><img style="border: 0; position: fixed; right: 0; top:0; z-index: 9000" src=https://d379ifj7s9wntv.cloudfront.net/reactivemanifesto/images/ribbons/we-are-reactive-black-right.png></a> <a id=skippy class="sr-only sr-only-focusable" href=#content><div class=container><span class=skiplink-text>Skip to main content</span></div></a><header class="navbar navbar-default navbar-static-top" id=top role=banner><div class=container><div class=navbar-header><button class="navbar-toggle collapsed" type=button data-toggle=collapse data-target=#vertx-navbar-collapse><span class=sr-only>Toggle navigation</span> <span class=icon-bar></span> <span class=icon-bar></span> <span class=icon-bar></span></button> <a href="https://vertx.tk/" class=navbar-brand><img alt=Brand src=https://vertx.tk/assets/logo-sm.png></a></div><nav class="collapse navbar-collapse" id=vertx-navbar-collapse><ul class="nav navbar-nav navbar-right"><li><a href=http://start.vertx.io>Starter</a></li><li><a href="https://vertx.tk/download/">下载</a></li><li><a href="https://vertx.tk/docs/">文档</a></li><li><a href=https://github.com/vert-x3/wiki/wiki>维基</a></li><li><a href="https://vertx.tk/community/">社区</a></li><li><a href="https://vertx.tk/materials/">资料</a></li><li><a href="https://vertx.tk/blog/">博客</a></li></ul></nav></div></header><div class=container><div class="row blog"><article class="col-xs-12 blog-post"><h2 class=blog-post-title>Centralized logging for Vert.x applications using the ELK stack</h2><p class=blog-post-meta>8th September 2016 by <a href=http://github.com/ricardohmon>ricardohmon</a></p><article><p>This post entry describes a solution to achieve centralized logging of Vert.x applications using the <a href=https://www.elastic.co/webinars/introduction-elk-stack>ELK stack</a>, a set of tools including Logstash, Elasticsearch, and Kibana that are well known to work together seamlessly.</p><h2 id=table-of-contents>Table of contents</h2><ul><li><a href=#preamble>Preamble</a></li><li><a href=#introduction>Introduction</a></li><li><a href=#overview>Overview</a></li><li><a href=#app-logging-configuration>App logging configuration</a><ul><li><a href=#log4j-logging>Log4j logging</a></li><li><a href=#filebeat-configuration>Filebeat configuration</a></li></ul></li><li><a href=#elk-configuration>ELK configuration</a><ul><li><a href=#logstash>Logstash</a></li><li><a href=#elasticsearch>Elasticsearch</a></li><li><a href=#kibana>Kibana</a></li></ul></li><li><a href=#log-shipping-challenge>Log shipping challenge</a></li><li><a href=#demo>Demo</a><ul><li><a href=#installation>Installation</a></li><li><a href=#building-the-example>Building the example</a></li><li><a href=#building-the-vertx-microservices-workshop-docker-images>Building the Vert.x Microservices workshop Docker images</a></li><li><a href=#running-the-example>Running the example</a></li><li><a href=#the-demo>The demo</a></li></ul></li><li><a href=#conclusion>Conclusion</a></li></ul><h2 id=preamble>Preamble</h2><p>This post was written in context of the project titled “<a href=https://summerofcode.withgoogle.com/projects/#4858492141699072>DevOps tooling for Vert.x applications</a>“, one of the Vert.x projects taking place during the 2016 edition of <a href="https://summerofcode.withgoogle.com/about/">Google Summer of Code</a>, a program that aims to bring together students with open source organizations, in order to help them to gain exposure to software development practices and real-world challenges.</p><h2 id=introduction>Introduction</h2><p>Centralized logging is an important topic while building a Microservices architecture and it is a step forward to adopting the DevOps culture. Having an overall solution partitioned into a set of services distributed across the Internet can represent a challenge when trying to monitor the log output of each of them, hence, a tool that helps to accomplish this results very helpful.</p><h2 id=overview>Overview</h2><p>As shown in the diagram below, the general centralized logging solution comprises two main elements: the application server, which runs our Vert.x application; and a separate server, hosting the ELK stack. Both elements are linked by Filebeat, a highly configurable tool capable of shipping our application logs to the Logstash instance, i.e., our gateway to the ELK stack.</p><p><img src=/assets/blog/centralized-logging-using-elk/elk-overview.svg alt="Overview of centralized logging with ELK"></p><h2 id=app-logging-configuration>App logging configuration</h2><p>The approach described here is based on a Filebeat + Logstash configuration, that means first we need to make sure our app logs to a file, whose records will be shipped to Logstash by Filebeat. Luckily, Vert.x provides the means to <a href=https://vertx.tk/docs/vertx-core/java/#_logging>configure</a> alternative logging frameworks (e.g., Log4j, Log4j2 and SLF4J) besides the default JUL logging. However, we can use Filebeat independently of the logging framework chosen.</p><h3 id=log4j-logging>Log4j Logging</h3><p>The demo that accompanies this post relies on Log4j2 as the logging framework. We instructed Vert.x to use this framework following the <a href=https://vertx.tk/docs/vertx-core/java/#_logging>guidelines</a> and we made sure our logging calls are made asynchronous, since we don’t want them to block our application. For this purpose, we opted for the <code>AsyncAppender</code> and this was included in the Log4J configuration together with the log output format described in a XML configuration available in the application’s <em>Resource</em> folder.</p><pre><code class="hljs xml"><span class=hljs-tag>&lt;<span class=hljs-title>Configuration</span>&gt;</span>
  <span class=hljs-tag>&lt;<span class=hljs-title>Appenders</span>&gt;</span>
    <span class=hljs-tag>&lt;<span class=hljs-title>RollingFile</span> <span class=hljs-attribute>name</span>=<span class=hljs-value>"vertx_logs"</span> <span class=hljs-attribute>append</span>=<span class=hljs-value>"true"</span> <span class=hljs-attribute>fileName</span>=<span class=hljs-value>"/var/log/vertx.log"</span> <span class=hljs-attribute>filePattern</span>=<span class=hljs-value>"/var/log/vertx/$${date:yyyy-MM}/vertx-%d{MM-dd-yyyy}-%i.log.gz"</span>&gt;</span>
      <span class=hljs-tag>&lt;<span class=hljs-title>PatternLayout</span> <span class=hljs-attribute>pattern</span>=<span class=hljs-value>"%d{ISO8601} %-5p %c:%L - %m%n"</span> /&gt;</span>
    <span class=hljs-tag>&lt;/<span class=hljs-title>RollingFile</span>&gt;</span>
    <span class=hljs-tag>&lt;<span class=hljs-title>Async</span> <span class=hljs-attribute>name</span>=<span class=hljs-value>"vertx_async"</span>&gt;</span>
      <span class=hljs-tag>&lt;<span class=hljs-title>AppenderRef</span> <span class=hljs-attribute>ref</span>=<span class=hljs-value>"vertx_logs"</span>/&gt;</span>
    <span class=hljs-tag>&lt;/<span class=hljs-title>Async</span>&gt;</span>
  <span class=hljs-tag>&lt;/<span class=hljs-title>Appenders</span>&gt;</span>
  <span class=hljs-tag>&lt;<span class=hljs-title>Loggers</span>&gt;</span>
    <span class=hljs-tag>&lt;<span class=hljs-title>Root</span> <span class=hljs-attribute>level</span>=<span class=hljs-value>"DEBUG"</span>&gt;</span>
      <span class=hljs-tag>&lt;<span class=hljs-title>AppenderRef</span> <span class=hljs-attribute>ref</span>=<span class=hljs-value>"vertx_async"</span> /&gt;</span>
    <span class=hljs-tag>&lt;/<span class=hljs-title>Root</span>&gt;</span>
  <span class=hljs-tag>&lt;/<span class=hljs-title>Loggers</span>&gt;</span>
<span class=hljs-tag>&lt;/<span class=hljs-title>Configuration</span>&gt;</span></code></pre><h3 id=filebeat-configuration>Filebeat configuration</h3><p>Now that we have configured the log output of our Vert.x application to be stored in the file system, we delegate to Filebeat the task of forwarding the logs to the Logstash instance. Filebeat can be configured through a YAML file containing the logs output location and the pattern to interpret multiline logs (i.e., stack traces). Also, the Logstash output plugin is configured with the host location and a secure connection is enforced using the certificate from the machine hosting Logstash. We set the <code>document_type</code> to the type of instance that this log belongs to, which could later help us while indexing our logs inside Elasticsearch.</p><pre><code><span class=hljs-attribute>filebeat</span>:
  <span class=hljs-attribute>prospectors</span>:
    -
      <span class=hljs-attribute>document_type</span>: trader_dashboard
      <span class=hljs-attribute>paths</span>:
        - /var/log/vertx.log
      <span class=hljs-attribute>multiline</span>:
        <span class=hljs-attribute>pattern</span>: <span class=hljs-string>"^[0-9]+"</span>
        <span class=hljs-attribute>negate</span>: true
        <span class=hljs-attribute>match</span>: after
<span class=hljs-attribute>output</span>:
  <span class=hljs-attribute>logstash</span>:
    <span class=hljs-attribute>enabled</span>: true
    <span class=hljs-attribute>hosts</span>:
      - <span class=hljs-attribute>elk</span>:<span class=hljs-number>5044</span>
    <span class=hljs-attribute>timeout</span>: <span class=hljs-number>15</span>
    <span class=hljs-attribute>tls</span>:
      <span class=hljs-attribute>insecure</span>: false
      <span class=hljs-attribute>certificate_authoritites</span>:
        - /etc/pki/tls/certs/logstash-beats.crt</code></pre><h2 id=elk-configuration>ELK configuration</h2><p>To take fully advantage of the ELK stack with respect to Vert.x and our app logs, we need to configure each of its individual components, namely Logstash, Elasticsearch and Kibana.</p><h3 id=logstash>Logstash</h3><p>Logstash is the component within the ELK stack that is in charge of aggregating the logs from each of the sources and forwarding them to the Elasticsearch instance.<br>Configuring Logstash is straightforward with the help of the specific input and output plugins for Beats and Elasticsearch, respectively. In the previous section we mentioned that Filebeat could be easily coupled with Logstash. Now, we see that this can be done by just specifying <code>Beat</code> as the input plugin and set the parameters needed to be reached by our shippers (listening port, ssl key and certificate location).</p><pre><code class="hljs bash">input {
  beats {
    port =&gt; <span class=hljs-number>5044</span>
    ssl =&gt; <span class=hljs-literal>true</span>
    ssl_certificate =&gt; <span class=hljs-string>"/etc/pki/tls/certs/logstash-beats.crt"</span>
    ssl_key =&gt; <span class=hljs-string>"/etc/pki/tls/private/logstash-beats.key"</span>
  }
}</code></pre><p>Now that we are ready to receive logs from the app, we can use Logstash filtering capabilities to specify the format of our logs and extract the fields so they can be indexed more efficiently by Elasticsearch.<br>The <code>grok</code> filtering plugin comes handy in this situation. This plugin allows to declare the logs format using predefined and customized patterns based in regular expressions allowing to declare new fields from the information extracted from each log line. In the following block, we instruct Logstash to recognize our Log4j pattern inside a <code>message</code> field, which contains the log message shipped by Filebeat. After that, the <code>date</code> filtering plugin parses the <code>timestamp</code> field extracted in the previous step and replaces it for the one set by Filebeat after reading the log output file.</p><pre><code class="hljs bash">filter {
  grok {
    <span class=hljs-keyword>break</span>_on_match =&gt; <span class=hljs-literal>false</span>
    match =&gt;  [ <span class=hljs-string>"message"</span>, <span class=hljs-string>"%{LOG4J}"</span>]
  }
  date{
    match =&gt; [ <span class=hljs-string>"timestamp_string"</span>, <span class=hljs-string>"ISO8601"</span>]
    remove_field =&gt; [ <span class=hljs-string>"timestamp_string"</span> ]
  }
}</code></pre><p>The Log4j pattern is not included within the Logstash configuration, however, we can specify it using predefined data formats shipped with Logstash and adapt it to the specific log formats required in our application, as shown next.</p><pre><code class=hljs><span class=hljs-header># Pattern to match our Log4j format</span>
SPACING (?:[\s]+)
LOGGER (?:[<span class=hljs-link_label>a-zA-Z$_</span>][<span class=hljs-link_reference>a-zA-Z$_0-9</span>]<span class=hljs-emphasis>*\.)*</span>[<span class=hljs-link_label>a-zA-Z$_</span>][<span class=hljs-link_reference>a-zA-Z$_0-9</span>]*
LINE %{INT}?
LOG4J %{TIMESTAMP<span class=hljs-emphasis>_ISO8601:timestamp_</span>string} %{LOGLEVEL:log<span class=hljs-emphasis>_level}%{SPACING}%{LOGGER:logger_</span>name}:%{LINE:loc<span class=hljs-emphasis>_line} - %{JAVALOGMESSAGE:log_</span>message}</code></pre><p>Finally, we take a look at Logstash’s output configuration. This simply points to our elasticsearch instance, instructs it to provide a list of all cluster nodes (<code>sniffing</code>), defines the name pattern for our indices, assigns the document type according to the metadata coming from Filebeat, and allows to define a custom index template for our data.</p><pre><code class=hljs>output {
  elasticsearch {
    hosts =&gt; [<span class=hljs-string>"localhost"</span>]
    sniffing =&gt; <span class=hljs-literal>true</span>
    manage_template =&gt; <span class=hljs-literal>true</span>
    index =&gt; <span class=hljs-string>"%{[@metadata][beat]}-%{+YYYY.MM.dd}"</span>
    document_type =&gt; <span class=hljs-string>"%{[@metadata][type]}"</span>
    <span class=hljs-keyword>template</span> =&gt; <span class=hljs-string>"/etc/filebeat/vertx_app_filebeat.json"</span>
    template_overwrite =&gt; <span class=hljs-literal>true</span>
  }
}</code></pre><h3 id=elasticsearch>Elasticsearch</h3><p>Elasticsearch is the central component that enables the efficient indexing and real-time search capabilities of the stack. To take the most advantage of Elasticsearch, we can provide an indexing template of our incoming logs, which can help to optimize the data storage and match the queries issued by Kibana at a later point.<br>In the example below, we see an index template that would be applied to any index matching the pattern <code>filebeat-*</code>. Additionally, we declare our new log fields <code>type</code>, <code>host</code>, <code>log_level</code>, <code>logger_name</code>, and <code>log_message</code>, which are set as <code>not_analyzed</code> except for the last two that are set as <code>analyzed</code> allowing to perform queries based on regular expressions and not restricted to query the full text.</p><pre><code class="hljs json">{
  "<span class=hljs-attribute>mappings</span>": <span class=hljs-value>{
    "<span class=hljs-attribute>_default_</span>": <span class=hljs-value>{
      "<span class=hljs-attribute>_all</span>": <span class=hljs-value>{
        "<span class=hljs-attribute>enabled</span>": <span class=hljs-value><span class=hljs-literal>true</span></span>,
        "<span class=hljs-attribute>norms</span>": <span class=hljs-value>{
          "<span class=hljs-attribute>enabled</span>": <span class=hljs-value><span class=hljs-literal>false</span>
        </span>}
      </span>}</span>,
      "<span class=hljs-attribute>dynamic_templates</span>": <span class=hljs-value>[
        {
          "<span class=hljs-attribute>template1</span>": <span class=hljs-value>{
            "<span class=hljs-attribute>mapping</span>": <span class=hljs-value>{
              "<span class=hljs-attribute>doc_values</span>": <span class=hljs-value><span class=hljs-literal>true</span></span>,
              "<span class=hljs-attribute>ignore_above</span>": <span class=hljs-value><span class=hljs-number>1024</span></span>,
              "<span class=hljs-attribute>index</span>": <span class=hljs-value><span class=hljs-string>"not_analyzed"</span></span>,
              "<span class=hljs-attribute>type</span>": <span class=hljs-value><span class=hljs-string>"{dynamic_type}"</span>
            </span>}</span>,
            "<span class=hljs-attribute>match</span>": <span class=hljs-value><span class=hljs-string>"*"</span>
          </span>}
        </span>}
      ]</span>,
      "<span class=hljs-attribute>properties</span>": <span class=hljs-value>{
        "<span class=hljs-attribute>@timestamp</span>": <span class=hljs-value>{
          "<span class=hljs-attribute>type</span>": <span class=hljs-value><span class=hljs-string>"date"</span>
        </span>}</span>,
        "<span class=hljs-attribute>offset</span>": <span class=hljs-value>{
          "<span class=hljs-attribute>type</span>": <span class=hljs-value><span class=hljs-string>"long"</span></span>,
          "<span class=hljs-attribute>doc_values</span>": <span class=hljs-value><span class=hljs-string>"true"</span>
        </span>}</span>,
        "<span class=hljs-attribute>type</span>": <span class=hljs-value>{ "<span class=hljs-attribute>type</span>": <span class=hljs-value><span class=hljs-string>"string"</span></span>, "<span class=hljs-attribute>index</span>": <span class=hljs-value><span class=hljs-string>"not_analyzed"</span> </span>}</span>,
        "<span class=hljs-attribute>host</span>": <span class=hljs-value>{ "<span class=hljs-attribute>type</span>": <span class=hljs-value><span class=hljs-string>"string"</span></span>, "<span class=hljs-attribute>index</span>": <span class=hljs-value><span class=hljs-string>"not_analyzed"</span> </span>}</span>,
        "<span class=hljs-attribute>log_level</span>": <span class=hljs-value>{ "<span class=hljs-attribute>type</span>": <span class=hljs-value><span class=hljs-string>"string"</span></span>, "<span class=hljs-attribute>index</span>": <span class=hljs-value><span class=hljs-string>"not_analyzed"</span> </span>}</span>,
        "<span class=hljs-attribute>logger_name</span>": <span class=hljs-value>{ "<span class=hljs-attribute>type</span>": <span class=hljs-value><span class=hljs-string>"string"</span></span>, "<span class=hljs-attribute>index</span>": <span class=hljs-value><span class=hljs-string>"analyzed"</span> </span>}</span>,
        "<span class=hljs-attribute>log_message</span>": <span class=hljs-value>{ "<span class=hljs-attribute>type</span>": <span class=hljs-value><span class=hljs-string>"string"</span></span>, "<span class=hljs-attribute>index</span>": <span class=hljs-value><span class=hljs-string>"analyzed"</span> </span>}
      </span>}
    </span>}
  </span>}</span>,
  "<span class=hljs-attribute>settings</span>": <span class=hljs-value>{
    "<span class=hljs-attribute>index.refresh_interval</span>": <span class=hljs-value><span class=hljs-string>"5s"</span>
  </span>}</span>,
  "<span class=hljs-attribute>template</span>": <span class=hljs-value><span class=hljs-string>"filebeat-*"</span>
</span>}</code></pre><h3 id=kibana>Kibana</h3><p>Although we could fetch all our logs from Elasticsearch through its API, Kibana is a powerful tool that allows a more friendly query and visualization. Besides the option to query our data through the available indexed field names and search boxes allowing typing specific queries, Kibana allows creating our own <em>Visualizations</em> and <em>Dashboards</em>. Combined, they represent a powerful way to display data and gain insight in a customized manner. The accompanied demo ships with a couple of sample dashboards and visualizations that take advantage of the log fields that we specified in our index template and throw valuable insight. This includes: visualizing the number of log messages received by ELK, observe the proportion of messages that each log source produces, and directly find out the sources of error logs.</p><p><img src=/assets/blog/centralized-logging-using-elk/kibana-dashboard.png alt="Kibana Dashboard" style="width: 70%; display: block; margin: auto"></p><h2 id=log-shipping-challenge>Log shipping challenge</h2><p>The solution presented here relied on Filebeat to ship log data to Logstash. However, if you are familiar with the Log4j framework you may be aware that there exists a <em>SocketAppender</em> that allows to write log events directly to a remote server using a TCP connection. Although including the Filebeat + Logstash combination may sound an unnecessary overhead to the logging pipeline, they provide a number of benefits in comparison to the Log4j socket alternative:</p><ul><li>The SocketAppender relies on the specific serialization of Log4j’s <em>LogEvent</em> objects, which is no an interchangeable format as JSON, which is used by the Beats solution. Although there are <a href=https://github.com/majikthys/log4j2-logstash-jsonevent-layout>attempts</a> to output the logs in a JSON format for Logstash, it doesn’t support multiline logs, which results in messages being split into different events by Logstash. On the other hand, there is no official nor stable <a href=https://www.elastic.co/guide/en/logstash/current/input-plugins.html>input plugin</a> for Log4j version 2.</li><li>While enabling Log4j’s async logging mode in an application delegates logging operations to separate threads, given their coexistence in the same JVM there is still the risk of data loss in case of a sudden JVM termination without proper log channel closing.</li><li>Filebeat is a data shipper designed to deal with many constraints that arise in distributed environments in a reliable manner, therefore it provides options to tailor and scale this operation to our needs: the possibility to load balance between multiple Logstash instances, specify the number of simultaneous Filebeat workers that ship log files, and specify a compression level in order to reduce the consumed bandwidth. Besides that, logs can be shipped in specific batch sizes, with maximum amount of retries, and specifying a connection timeout.</li><li>Lastly, although Filebeat can forward logs directly to Elasticsearch, using Logstash as an intermediary offers the possibility to collect logs from diverse sources (e.g., system metrics).</li></ul><h2 id=demo>Demo</h2><p>This post is accompanied by a demo based on the Vert.x Microservices <a href="http://vertx-lab.dynamis-technologies.com/">workshop</a>, where each of them is shipped in a Docker container simulating a distributed system composed of independent addressable nodes.<br>Also, the ELK stack is provisioned using a preconfigured Docker image by <a href=https://github.com/spujadas>Sébastien Pujadas</a>.</p><p>Following the guidelines in this post, this demo configures each of the Microservices of the workshop, sets up a Filebeat process on each of them to ship the logs to a central container hosting the ELK stack.</p><h3 id=installation>Installation</h3><p>In order to run this demo, it is necessary to have Docker installed, then proceed with:</p><ul><li>Cloning or downloading the demo <a href=https://github.com/ricardohmon/vertx-elk>repository</a>.</li><li>Separately, obtaining the source code of the <a href=https://github.com/ricardohmon/vertx-microservices-workshop/tree/elk-demo>branch</a> of the Microservices workshop adapted for this demo.</li></ul><h3 id=building-the-example>Building the example</h3><p>The Docker images belonging to the Vert.x Microservices workshop need to be built separately to this project before this project can be launched.</p><h3 id=building-the-vert-x-microservices-workshop-docker-images->Building the Vert.x Microservices workshop Docker images.</h3><p>Build the <em>root</em> project and the <em>Trader Dashboard</em> followed by each of the modules contained in the solution folder. Issue the following commands for this:</p><pre><code class=hljs>mvn clean install
cd trader-dashboard
mvn <span class=hljs-keyword>package</span> <span class=hljs-string>docker:</span>build
cd ..<span class=hljs-regexp>/solution/</span>audit-service
mvn <span class=hljs-keyword>package</span> <span class=hljs-string>docker:</span>build
cd ../compulsive-traders
mvn <span class=hljs-keyword>package</span> <span class=hljs-string>docker:</span>build
cd ../portfolio-service
mvn <span class=hljs-keyword>package</span> <span class=hljs-string>docker:</span>build
cd ..<span class=hljs-regexp>/quote-generator/</span>
mvn <span class=hljs-keyword>package</span> <span class=hljs-string>docker:</span>build</code></pre><h3 id=running-the-example>Running the example</h3><p>After building the previous images, build and run the example in <code>vertx-elk</code> using the following command:</p><pre><code class=hljs>docker-compose <span class=hljs-keyword>up</span></code></pre><h3 id=the-demo>The demo</h3><p>You can watch the demo in action in the following screencast:</p><div class="embed-responsive embed-responsive-16by9"><iframe class=embed-responsive-item src=https://www.youtube.com/embed/8P-MgXSujes frameborder=0 allowfullscreen></iframe></div><h2 id=conclusion>Conclusion</h2><p>The ELK stack is a powerful set of tools that ease the aggregation of logs coming from distributed services into a central server. Its main pillar, Elasticsearch, provides the indexing and search capabilities of our log data. Also, it is accompanied by the convenient input/output components: Logstash, which can be flexibly configured to accept different data sources; and Kibana, which can be customized to present the information in the most convenient way.</p><p>Logstash has been designed to work seamlessly with Filebeat, the log shipper which represents a robust solution that can be adapted to our applications without having to make <em>significant</em> changes to our architecture. In addition, Logstash can accept varied types of sources, filter the data, and process it before delivering to Elasticsearch. This flexibility comes with the price of having extra elements in our log aggregation pipeline, which can represent an increase of processing overhead or a point-of-failure. This additional overhead could be avoided if an application would be capable of delivering its log output directly to Elasticsearch.</p><p>Happy logging!</p></article></article></div><div class=row><div class=col-xs-12 id=disqus_thread></div></div><script>var disqus_config = function () {
  this.page.url = "https://vertx.tk/blog/centralized-logging-for-vert-x-applications-using-the-elk-stack/";
  this.page.identifier = "/blog/centralized-logging-for-vert-x-applications-using-the-elk-stack/";
  };
  (function() { // DON'T EDIT BELOW THIS LINE
  var d = document, s = d.createElement('script');
  s.src = 'https://vertx.disqus.com/embed.js';
  s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
  })();</script><noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><footer><div class=container><div class=row><div class="col-xs-4 col-sm-4 col-md-2 col-lg-2"><h2>Eclipse Vert.x</h2><ul class=list-unstyled><li><a href="https://vertx.tk/">主页</a></li><li><a href="https://vertx.tk/download/">下载</a></li><li><a href="https://vertx.tk/docs/">文档</a></li><li><a href=https://github.com/vert-x3/wiki/wiki>维基</a></li><li><a href="https://vertx.tk/blog/">博客</a></li></ul></div><div class="col-xs-4 col-sm-4 col-md-2 col-lg-2"><h2>Community</h2><ul class=list-unstyled><li><a href="https://vertx.tk/community/">Help &amp; Contributors</a></li><li><a href="https://vertx.tk/materials/">Learning materials</a></li><li><a href=https://groups.google.com/forum/?fromgroups#!forum/vertx>User Group</a></li><li><a href=https://groups.google.com/forum/?fromgroups#!forum/vertx-dev>Developer Group</a></li><li><a href="//shang.qq.com/wpa/qunwpa?idkey=587f58cacb9557e3291b46098e0fe09427b98a1c0f866da23c04c2762bc7e2ad">QQ群</a></li></ul></div><div class="col-xs-4 col-sm-4 col-md-2 col-lg-2"><h2>Eclipse</h2><ul class=list-unstyled><li><a href="http://www.eclipse.org/">Eclipse Foundation</a></li><li><a href=https://eclipse.org/legal/privacy.php>Privacy Policy</a></li><li><a href=https://eclipse.org/legal/termsofuse.php>Terms of Use</a></li><li><a href=https://eclipse.org/legal/copyright.php>Copyright Agent</a></li><li><a href=http://www.eclipse.org/legal>Legal Resources</a></li></ul></div><div class="col-xs-12 col-sm-12 col-md-6 col-lg-6 copyright"><p>Eclipse Vert.x is open source and dual-licensed under the <a href=http://www.eclipse.org/legal/epl-v20.html>Eclipse Public License 2.0</a> and <a href=https://www.apache.org/licenses/LICENSE-2.0.html>Apache License 2.0</a>.</p><p>This website is licensed under the <a href="http://creativecommons.org/licenses/by-sa/3.0/">CC BY-SA 3.0 License</a>.<br>Design by <a href=https://www.michel-kraemer.com>Michel Kr&auml;mer</a>.</p><div class=row><div class="col-sm-12 col-md-5 col-md-offset-1 col-lg-offset-2"><a href=http://eclipse.org><img class="logo eclipse-logo" src=https://vertx.tk/assets/eclipse_logo_grey_small.png width=204 height=48></a></div><div class="col-sm-12 col-md-5 col-md-offset-1 col-lg-offset-0"><a href=http://cloudbees.com><img class="logo cloudbees-logo" src=https://vertx.tk/assets/Button-Built-on-CB-1-grey.png width=180 height=48></a></div><div class="col-sm-12 col-md-5 col-md-offset-7 jprofiler"><a href=http://www.ej-technologies.com/products/jprofiler/overview.html style=text-decoration:none><img class="logo jprofiler-logo" src=https://vertx.tk/assets/jprofiler-logo.png width=48 height=48><span class=jprofiler-logo>&nbsp; JPROFILER</span></a></div></div></div></div></div></footer><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery/1.9.1/jquery.min.js></script><script src=https://vertx.tk/javascripts/bootstrap.min.js></script><script src=https://vertx.tk/javascripts/highlight.pack.js></script><script>hljs.initHighlightingOnLoad();</script><link rel=stylesheet type=text/css href="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.0.3/cookieconsent.min.css"><script src=//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.0.3/cookieconsent.min.js></script><script>window.addEventListener("load", function(){
window.cookieconsent.initialise({
  "palette": {
    "popup": {
      "background": "#64386b",
      "text": "#ffcdfd"
    },
    "button": {
      "background": "transparent",
      "text": "#f8a8ff",
      "border": "#f8a8ff"
    }
  },
  "content": {
    "message": "This website uses anonymous cookies to ensure we provide you the best experience. ",
    "link": "Opt out!",
    "href": "https://tools.google.com/dlpage/gaoptout/"
  }
})});</script></body></html>